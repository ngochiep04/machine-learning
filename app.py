import streamlit as st
import pandas as pd
import joblib

# T·∫£i m√¥ h√¨nh v√† c√°c th√†nh ph·∫ßn li√™n quan

from xgboost import XGBClassifier
model = XGBClassifier()
model.load_model("xgb_model.json")
model.n_classes_ = 3
scaler = joblib.load("scaler.pkl")
feature_columns = joblib.load("feature_columns.pkl")

st.set_page_config(page_title="D·ª± ƒëo√°n kh√°ch h√†ng", layout="wide")

# Nh√£n hi·ªÉn th·ªã cho c√°c tr∆∞·ªùng
label_map = {
    "Tuoi": "Tu·ªïi",
    "Thu_nhap": "Thu nh·∫≠p",
    "Chi_tieu": "Chi ti√™u",
    "Tien_dien": "Ti·ªÅn ƒëi·ªán",
    "So_tien_vay": "S·ªë ti·ªÅn vay",
    "Th_kvay": "Th·ªùi h·∫°n kho·∫£n vay",
    "Nguoi_phu_thuoc": "S·ªë ng∆∞·ªùi ph·ª• thu·ªôc",
    "Tt_cv": "T√¨nh tr·∫°ng c√¥ng vi·ªác",
    "Tt_hon_nhan": "T√¨nh tr·∫°ng h√¥n nh√¢n",
    "Ts_the_chap": "T√†i s·∫£n th·∫ø ch·∫•p",
    "Tt_sh_nha": "T√¨nh tr·∫°ng s·ªü h·ªØu nh√†",
    "Md_vay": "M·ª•c ƒë√≠ch vay",
    "Cm_thu_nhap": "Ch·ª©ng minh thu nh·∫≠p",
    "Td_hoc_van": "Tr√¨nh ƒë·ªô h·ªçc v·∫•n"
}

# C√°c ƒë·∫∑c tr∆∞ng nh·∫≠p s·ªë
numeric_features = [
    "Tuoi", "Thu_nhap", "Chi_tieu", "Tien_dien",
    "So_tien_vay", "Th_kvay", "Nguoi_phu_thuoc"
]

# C√°c ƒë·∫∑c tr∆∞ng ph√¢n lo·∫°i c·∫ßn √°nh x·∫°
categorical_mappings = {
    "Tt_cv": [str(i) for i in range(1, 21)],
    "Tt_hon_nhan": {
        "C√≥ gia ƒë√¨nh": 1,
        "ƒê·ªôc th√¢n": 2,
        "Ly h√¥n": 3,
        "G√≥a": 4
    },
    "Ts_the_chap": {
        "C√≥ t√†i s·∫£n th·∫ø ch·∫•p": 0,
        "Kh√¥ng c√≥ t√†i s·∫£n th·∫ø ch·∫•p": 1
    },
    "Tt_sh_nha": {
        "ƒê√£ s·ªü h·ªØu nh√† ·ªü": 0,
        "Ch∆∞a s·ªü h·ªØu nh√† ·ªü": 1
    },
    "Md_vay": {
        "Ti√™u d√πng": 1,
        "H·ªçc t·∫≠p": 2,
        "S·∫£n xu·∫•t kinh doanh": 3,
        "Mua xe": 4,
        "Mua nh√†": 5,
        "ƒê·∫ßu t∆∞ ch·ª©ng kho√°n": 6
    },
    "Cm_thu_nhap": {
        "C√≥ gi·∫•y t·ªù ch·ª©ng minh": 0,
        "Kh√¥ng c√≥ gi·∫•y t·ªù ch·ª©ng minh": 1
    },
    "Td_hoc_van": {
        "Ti·∫øn sƒ©": 1,
        "Th·∫°c sƒ©": 2,
        "ƒê·∫°i h·ªçc": 3,
        "C·∫•p ba": 4
    }
}

# Giao di·ªán nh·∫≠p li·ªáu
st.subheader("üì• Nh·∫≠p th√¥ng tin kh√°ch h√†ng")
user_input = {}

# Nh·∫≠p s·ªë: chia th√†nh 2 d√≤ng
cols_num = st.columns(4)
for i, feature in enumerate(numeric_features):
    with cols_num[i % 4]:
        user_input[feature] = st.number_input(label_map[feature], value=0, step=1)

# Ch·ªçn dropdown: chia th√†nh 3‚Äì4 d√≤ng
cat_features = list(categorical_mappings.keys())
for row in range(0, len(cat_features), 3):
    cols_cat = st.columns(3)
    for i, feature in enumerate(cat_features[row:row+3]):
        with cols_cat[i]:
            options = list(categorical_mappings[feature].keys()) if isinstance(categorical_mappings[feature], dict) else categorical_mappings[feature]
            selected = st.selectbox(label_map[feature], ["Ch·ªçn"] + options)
            if selected != "Ch·ªçn":
                user_input[feature] = categorical_mappings[feature][selected] if isinstance(categorical_mappings[feature], dict) else int(selected)
            else:
                user_input[feature] = ""

# N√∫t d·ª± ƒëo√°n: ƒë·∫∑t gi·ªØa v√† l√†m to
st.markdown("<br>", unsafe_allow_html=True)
centered_button = st.columns([1, 2, 1])[1]
with centered_button:
    if st.button("üîç D·ª∞ ƒêO√ÅN", use_container_width=True):
        missing_count = sum(v == "" or v == 0 for v in user_input.values())

        if missing_count == len(user_input):
            st.error("‚ö†Ô∏è H√£y nh·∫≠p th√¥ng tin kh√°ch h√†ng.")
        else:
            if missing_count > 3:
                st.warning("‚ö†Ô∏è B·∫°n ƒëang b·ªè tr·ªëng qu√° nhi·ªÅu th√¥ng tin, k·∫øt qu·∫£ d·ª± ƒëo√°n c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c.")

            # X·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫ßu v√†o
            input_df = pd.DataFrame([user_input])
            input_encoded = pd.get_dummies(input_df)
            input_encoded = input_encoded.reindex(columns=feature_columns, fill_value=0)
            input_encoded = input_encoded.fillna(0)
            input_encoded = input_encoded.astype(float)
            input_scaled = scaler.transform(input_encoded)
            prediction = model.predict(input_scaled)[0]

            label_mapping = {
                0: "Kh√¥ng th·ªÉ tr·∫£ n·ª£",
                1: "C√≥ th·ªÉ tr·∫£ n·ª£",
                2: "Ch·∫Øc ch·∫Øn tr·∫£ ƒë∆∞·ª£c n·ª£"
            }

            st.success(f"‚úÖ K·∫øt qu·∫£ d·ª± ƒëo√°n: {label_mapping[prediction]}")